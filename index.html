<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yaodong Yu</title>
</head>
<body style="width: 1000px; margin: 0 auto;">
<div id="fwtitle">
<div id="toptitle">
<h1>Yaodong Yu</h1>
</div>
</div>
<div id="layout-content">
<table class="imgtable"><tr><td>
<img src="photo_me_2.jpg" alt="photo_me" width="190px" height="200px" />&nbsp;</td>
<td align="left"><p>Graduate Student<br />
EECS Department, University of California, Berkeley</p>
<p>7th floor, Sutardja Dai Hall, Berkeley, CA 94720.<br />  
Email: yyu AT eecs DOT berkeley DOT edu</a>

</p>
</td></tr></table>
<h2>About me</h2>
<p>I am a PhD student in the EECS department at UC Berkeley advised by <a href="https://people.eecs.berkeley.edu/~jordan/">Michael I. Jordan</a> and <a href="http://people.eecs.berkeley.edu/~yima/">Yi Ma</a>. I obtained my B.S. from the Department of Mathematics at Nanjing University, and my M.S. from the Department of Computer Science</a>, University of Virginia. 
<!-- Previously, I was fortunate to work with <a href="http://www.ntu.edu.sg/home/sinnopan/">Sinno Jialin Pan</a> at Nanyang Technological University.  -->

</p>
My research interests include topics in machine learning and optimization. My goal is to make machine learning systems more robust.
</p>

<!-- <h2>News</h2>

<ul>
	   <li>
	   	[11/9/2018] We won the <b>1st place</b> in both Robust Model Track and Targeted Attack Track, as well as <b>the 3rd place</b> in Untargeted Attack Track in <a href="https://www.crowdai.org/challenges/nips-2018-adversarial-vision-challenge-robust-model-track">NeurIPS 2018 : Adversarial Vision Challenge</a> [<a href="https://medium.com/bethgelab/results-of-the-nips-adversarial-vision-challenge-2018-e1e21b690149">News Link</a>]. Congratulations to our team! Please check our new method <b>TRADES</b> [<a href="https://arxiv.org/abs/1901.08573">paper</a>] [<a href="https://github.com/yaodongyu/TRADES">code</a>].
       </li>
</ul> -->

<h2>Publications [<a href="https://scholar.google.com/citations?user=bZ9oyW8AAAAJ&hl=zh-CN&oi=ao">Google Scholar</a>]</h2> 

<!-- <h3>Preprints</h3>
<ul>
<li><p><i>Saving Gradient and Negative Curvature Computations: Finding Local Minima More Efficiently</i>.<br /> 
<b>Yaodong Yu</b>*, Difan Zou* and Quanquan Gu (*: equal contribution). arXiv:1712.03950, 2017. [<a href="https://arxiv.org/abs/1712.03950">arXiv</a>]<br /></p>
</li>
</ul> -->

<!-- <h3>Conference Proceedings</h3> -->
<ul>
<li><p><i>Predicting Out-of-Distribution Error with the Projection Norm</i>.<br />
<b>Yaodong Yu</b>*, Zitong Yang*, Alexander Wei, Yi Ma, Jacob Steinhardt (*: equal contribution). <br />  
In Proc. of the 39th International Conference on Machine Learning (ICML'2022), 2022. [<a href="https://proceedings.mlr.press/v162/yu22i.html">Link</a>] [<a href="https://proceedings.mlr.press/v162/yu22i/yu22i.pdf">PDF</a>] [<a href="https://github.com/yaodongyu/ProjNorm">code</a>] <br /></p>
</li>
</ul>
<ul>
<li><p><i>Online Nonsubmodular Minimization with Delayed Costs: From Full Information to Bandit Feedback</i>.<br />
Tianyi Lin*, Aldo Pacchiano*, <b>Yaodong Yu</b>*, Michael I. Jordan (*: equal contribution). <br />  
In Proc. of the 39th International Conference on Machine Learning (ICML'2022), 2022. [<a href="https://proceedings.mlr.press/v162/lin22g.html">Link</a>] [<a href="https://proceedings.mlr.press/v162/lin22g/lin22g.pdf">PDF</a>]  <br /></p>
</li>
</ul>
<ul>
<li><p><i>ReduNet: A White-box Deep Network from the Principle of Maximizing Rate Reduction</i>.<br />
Kwan Ho Ryan Chan*, <b>Yaodong Yu</b>*, Chong You*, Haozhi Qi, John Wright, Yi Ma (*: equal contribution). <br />  
Journal of Machine Learning Research (JMLR'2022), 2022. [<a href="https://arxiv.org/abs/2105.10446">arXiv</a>] [<a href="https://www.jmlr.org/papers/v23/21-0631.html">Link</a>] [<a href="https://arxiv.org/pdf/2105.10446.pdf">PDF</a>]  [<a href="https://github.com/Ma-Lab-Berkeley/ReduNet">code</a>] <br /></p>
</li>
</ul>
<ul>
<li><p><i>Fast Distributionally Robust Learning with Variance-Reduced Min-Max Optimization</i>.<br />
<b>Yaodong Yu</b>*, Tianyi Lin*, Eric Mazumdar*, Michael I. Jordan (*: equal contribution). <br />  
In Proc. of the 25nd of the International Conference on Artificial Intelligence and Statistics (AISTATS'2022), 2022. [<a href="https://proceedings.mlr.press/v151/yu22a">Link</a>] [<a href="https://proceedings.mlr.press/v151/yu22a/yu22a.pdf">PDF</a>] <br /></p>
</li>
</ul>
<ul>
<li><p><i>On the Convergence of Stochastic Extragradient for Bilinear Games with Restarted Iteration Averaging</i>.<br />
Chris Junchi Li*, <b>Yaodong Yu</b>*, Nicolas Loizou, Gauthier Gidel, Yi Ma, Nicolas Le Roux, Michael I. Jordan (*: equal contribution). <br />  
In Proc. of the 25nd of the International Conference on Artificial Intelligence and Statistics (AISTATS'2022), 2022. [<a href="https://proceedings.mlr.press/v151/junchi-li22a.html">Link</a>] [<a href="https://proceedings.mlr.press/v151/junchi-li22a/junchi-li22a.pdf">PDF</a>] <br /></p>
</li>
</ul>
<ul>
<li><p><i>Adversarial Robustness of Stabilized NeuralODEs Might be from Obfuscated Gradients</i>.<br />  Yifei Huang, <b>Yaodong Yu</b>, Hongyang Zhang, Yi Ma, and Yuan Yao.<br />  Mathematical and Scientific Machine Learning (MSML'2021), 2021. [<a href="https://proceedings.mlr.press/v145/huang22a.html">Link</a>] [<a href="https://proceedings.mlr.press/v145/huang22a/huang22a.pdf">PDF</a>] [<a href="https://github.com/yao-lab/SONet">code</a>] <br /></p>
</li>
</ul>
<ul>
<li><p><i>Learning Diverse and Discriminative Representations via the Principle of Maximal Coding Rate Reduction</i>.<br />  <b>Yaodong Yu</b>*, Kwan Ho Ryan Chan*, Chong You, Chaobing Song, Yi Ma (*: equal contribution).<br />  In Proc. of the 34th Conference on Advances in Neural Information Processing Systems (NeurIPS'2020), 2020. [<a href="https://arxiv.org/abs/2006.08558">arXiv</a>] [<a href="https://proceedings.neurips.cc/paper/2020/hash/6ad4174eba19ecb5fed17411a34ff5e6-Abstract.html">Link</a>] [<a href="https://proceedings.neurips.cc/paper/2020/file/6ad4174eba19ecb5fed17411a34ff5e6-Paper.pdf">PDF</a>] [<a href="https://github.com/ryanchankh/mcr2">code</a>] <br /></p>
</li>
</ul>
<ul>
<li><p><i>Boundary Thickness and Robustness in Learning Models</i>.<br /> Yaoqing Yang, Rajiv Khanna, <b>Yaodong Yu</b>, Amir Gholami, Kurt Keutzer, Joseph Gonzalez, Kannan Ramchandran, and Michael W Mahoney.<br />  In Proc. of the 34th Conference on Advances in Neural Information Processing Systems (NeurIPS'2020), 2020. [<a href="https://arxiv.org/abs/2007.05086">arXiv</a>] [<a href="https://papers.nips.cc/paper/2020/hash/44e76e99b5e194377e955b13fb12f630-Abstract.html">Link</a>] [<a href="https://proceedings.neurips.cc/paper/2020/file/44e76e99b5e194377e955b13fb12f630-Paper.pdf">PDF</a>] [<a href="https://github.com/nsfzyzz/boundary_thickness">code</a>] <br /></p>
</li>
</ul>
<ul>
<li><p><i>Rethinking Bias-Variance Trade-off for Generalization of Neural Networks</i>.<br /> Zitong Yang*, <b>Yaodong Yu</b>*, Chong You, Jacob Steinhardt, and Yi Ma (*: equal contribution).<br />  In Proc. of the 37th International Conference on Machine Learning (ICML'2020), 2020. [<a href="https://arxiv.org/abs/2002.11328">arXiv</a>] [<a href="https://proceedings.mlr.press/v119/yang20j">Link</a>] [<a href="http://proceedings.mlr.press/v119/yang20j/yang20j.pdf">PDF</a>] [<a href="https://github.com/yaodongyu/Rethink-BiasVariance-Tradeoff">code</a>] <br /></p>
</li>
</ul>
<ul>
<li><p><i>Theoretically Principled Trade-off between Robustness and Accuracy</i>.<br /> Hongyang Zhang, <b>Yaodong Yu</b>, Jiantao Jiao, Eric P. Xing, Laurent El Ghaoui and Michael I. Jordan. In Proc. of the 36th International Conference on Machine Learning (ICML'2019), Long Beach, California, USA, 2019. [<a href="https://arxiv.org/abs/1901.08573">arXiv</a>] [<a href="http://proceedings.mlr.press/v97/zhang19p">Link</a>] [<a href="http://proceedings.mlr.press/v97/zhang19p/zhang19p.pdf">PDF</a>] [<a href="https://github.com/yaodongyu/TRADES">code</a>] <br /></p>
</li>
</ul>
<ul>
<li><p><i>Learning One-hidden-layer ReLU Networks via Gradient Descent</i>.<br /> 
Xiao Zhang*, <b>Yaodong Yu</b>*, Lingxiao Wang* and Quanquan Gu (*: equal contribution). <br /> 
In Proc. of the 22nd International Conference on Artificial Intelligence and Statistics (AISTATS'2019), Naha, Okinawa, Japan, 2019. [<a href="http://proceedings.mlr.press/v89/zhang19g">Link</a>] [<a href="http://proceedings.mlr.press/v89/zhang19g/zhang19g.pdf">PDF</a>]
</li>
</ul>
<ul>
<li><p><i>Third-order Smoothness Helps: Faster Stochastic Optimization Algorithms for Finding Local Minima</i>.<br /> 
<b>Yaodong Yu</b>*, Pan Xu* and Quanquan Gu (*: equal contribution).<br />
In Proc. of the 32nd Conference on Advances in Neural Information Processing Systems (NeurIPS'2018), Montr√©al, Canada, 2018. [<a href="http://papers.nips.cc/paper/7704-third-order-smoothness-helps-faster-stochastic-optimization-algorithms-for-finding-local-minima">Link</a>] [<a href="http://papers.nips.cc/paper/7704-third-order-smoothness-helps-faster-stochastic-optimization-algorithms-for-finding-local-minima.pdf">PDF</a>][<a href="files_pdf/poster_FLASH.pdf">Poster</a>] <br /></p>
</li>
</ul>
<ul>
<li><p><i>A Primal-Dual Analysis of Global Optimality in Nonconvex Low-Rank Matrix Recovery</i>.<br /> 
Xiao Zhang*, Lingxiao Wang*, <b>Yaodong Yu</b> and Quanquan Gu (*: equal contribution).<br />
In Proc. of the 35th International Conference on Machine Learning (ICML'2018), Stockholm, Sweden, 2018. [<a href="http://proceedings.mlr.press/v80/zhang18m.html">Link</a>] [<a href="http://proceedings.mlr.press/v80/zhang18m/zhang18m.pdf">PDF</a>]<br /></p>
</li>
</ul>
<ul>
<li><p><i>Data Poisoning Attacks on Multi-Task Relationship Learning</i>.<br /> 
Mengchen Zhao, Bo An, <b>Yaodong Yu</b>, Sulin Liu and Sinno Jialin Pan.<br />
In Proc. of the 32nd AAAI Conference on Artificial Intelligence (AAAI'2018), New Orleans, Louisiana, USA, 2018. [<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16073">Link</a>] [<a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16073/16778">PDF</a>]<br /></p>
</li>
</ul>
<ul>
<li><p><i>Communication-Efficient Distributed Primal-Dual Algorithm for Saddle Point Problems</i>.<br /> 
<b>Yaodong Yu</b>*, Sulin Liu* and Sinno Jialin Pan (*: equal contribution).<br />
In Proc. of the 33rd Conference on Uncertainty in Artificial Intelligence (UAI'2017), Sydney, Australia, 2017. [<a href="http://auai.org/uai2017/proceedings/papers/286.pdf">Link</a>] [<a href="http://auai.org/uai2017/proceedings/papers/286.pdf">PDF</a>]<br /></p>
</li>
</ul>


</p>
</li>
</ul>
<h2>Professional Experiences</h2>
<ul>
<li><p><b>Research Intern</b>, <a href="https://ai.facebook.com">Meta AI</a>, San Francisco, May. 2022 &ndash; Aug. 2022<br />
</li>
<li><p><b>Research Intern</b>, <a href="https://research.google">Google Research</a>, Remote, May. 2021 &ndash; Aug. 2021<br />
</li>
<li><p><b>Research Intern</b>, <a href="http://petuum.com">Petuum</a>, Pittsburgh, PA, May. 2018 &ndash; Dec. 2018<br />
</li>
<li><p><b>Research Assistant</b>, <a href="http://scse.ntu.edu.sg/Pages/Home.aspx">School of Computer Science and Engineering</a>, <a href="http://www.ntu.edu.sg/Pages/home.aspx">Nanyang Technological University (NTU)</a>, Singapore, Sep. 2016 &ndash; Aug. 2017<br />
</li>
<li><p><b>Machine Learning Engineer</b>, <a href="https://www.wecash.net">Wecash</a>, Beijing, China, June 2015 &ndash; May. 2016<br />
</li>
</ul>




</div>
</body>
</html>
